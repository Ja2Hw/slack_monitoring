import os
import subprocess
import requests
import time
import yaml
from dotenv import load_dotenv

# .env íŒŒì¼ ë¡œë“œ
load_dotenv('server_ex.env')

# í™˜ê²½ ë³€ìˆ˜ ì½ê¸°
WEBHOOK_URL = os.getenv("SLACK_WEBHOOK_URL")
SERVER_NAME = os.getenv("SERVER_NAME", "Unknown Server")

if not WEBHOOK_URL:
    raise ValueError("SLACK_WEBHOOK_URL í™˜ê²½ ë³€ìˆ˜ê°€ ì„¤ì •ë˜ì§€ ì•Šì•˜ìŠµë‹ˆë‹¤.")

# ì„¤ì • ê°’
CHECK_INTERVAL = 60  # 1ë¶„ ê°„ê²©
ALERT_THRESHOLD = 5000  # 5GB (MB ë‹¨ìœ„)

# ë°ì´í„° ì €ì¥ ê²½ë¡œ ì„¤ì •
LOG_DIR = "monitor_log"
LOG_FILE = os.path.join(LOG_DIR, "gpu_status.log")
os.makedirs(LOG_DIR, exist_ok=True)

def get_gpu_memory_usage():
    """nvidia-smi ê¸°ë³¸ ëª…ë ¹ìœ¼ë¡œ GPU ë©”ëª¨ë¦¬ ì‚¬ìš©ëŸ‰ ê°€ì ¸ì˜¤ê¸°"""
    try:
        result = subprocess.run(["nvidia-smi"], capture_output=True, text=True)
        if result.returncode != 0:
            print("[ERROR] nvidia-smi ëª…ë ¹ ì‹¤í–‰ ì‹¤íŒ¨")
            return {}

        output = result.stdout
        gpu_usage = {}

        # GPU ì •ë³´ íŒŒì‹±
        lines = output.splitlines()
        gpu_index = -1
        for i, line in enumerate(lines):
            if "Tesla V100-SXM2-32GB" in line:  # GPU ëª¨ë¸ ì´ë¦„ ê¸°ì¤€ìœ¼ë¡œ íƒì§€
                gpu_index += 1
                gpu_usage[gpu_index] = 0  # ì´ˆê¸°í™”
            elif gpu_index >= 0 and "MiB" in line and "Default" in line:  # ë©”ëª¨ë¦¬ ì‚¬ìš©ëŸ‰ ê°ì§€
                try:
                    parts = line.split("|")
                    memory_info = parts[2].strip()  # "Memory-Usage" ë¶€ë¶„
                    used_memory = int(memory_info.split("/")[0].strip().replace("MiB", ""))
                    gpu_usage[gpu_index] = used_memory
                except (IndexError, ValueError) as e:
                    print(f"[ERROR] ë©”ëª¨ë¦¬ ì‚¬ìš©ëŸ‰ íŒŒì‹± ì‹¤íŒ¨: {line} ({e})")

        return gpu_usage
    except Exception as e:
        print(f"[ERROR] GPU ë©”ëª¨ë¦¬ ì‚¬ìš©ëŸ‰ ì¡°íšŒ ì¤‘ ì˜¤ë¥˜ ë°œìƒ: {e}")
        return {}

def get_gpu_process_info():
    """nvidia-smi --query-compute-appsë¥¼ í†µí•´ GPU í”„ë¡œì„¸ìŠ¤ ì •ë³´ ê°€ì ¸ì˜¤ê¸°"""
    try:
        result = subprocess.run(
            ["nvidia-smi", "--query-compute-apps=gpu_uuid,pid,used_memory", "--format=csv,noheader,nounits"],
            capture_output=True,
            text=True
        )
        if result.returncode != 0:
            print("[ERROR] nvidia-smi --query-compute-apps ëª…ë ¹ ì‹¤í–‰ ì‹¤íŒ¨")
            return {}

        lines = result.stdout.strip().split("\n")
        gpu_process_info = {}

        for line in lines:
            if not line.strip():
                continue

            gpu_uuid, pid, used_memory = line.split(", ")
            pid = int(pid)
            used_memory = int(used_memory)

            if gpu_uuid not in gpu_process_info:
                gpu_process_info[gpu_uuid] = {"used_memory": 0, "processes": []}

            gpu_process_info[gpu_uuid]["used_memory"] += used_memory
            gpu_process_info[gpu_uuid]["processes"].append({"pid": pid, "used_memory": used_memory})

        return gpu_process_info
    except Exception as e:
        print(f"[ERROR] GPU í”„ë¡œì„¸ìŠ¤ ì •ë³´ ì¡°íšŒ ì¤‘ ì˜¤ë¥˜ ë°œìƒ: {e}")
        return {}

def get_process_cwd(pid):
    """íŠ¹ì • PIDì˜ ì‘ì—… ë””ë ‰í† ë¦¬ ê°€ì ¸ì˜¤ê¸°"""
    try:
        cwd_path = os.readlink(f"/proc/{pid}/cwd")
        return cwd_path
    except FileNotFoundError:
        print(f"[DEBUG] PID {pid} ì‘ì—… ë””ë ‰í† ë¦¬ë¥¼ ì°¾ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤.")
        return None
    except Exception as e:
        print(f"[ERROR] PID {pid} ì‘ì—… ë””ë ‰í† ë¦¬ í™•ì¸ ì¤‘ ì˜¤ë¥˜ ë°œìƒ: {e}")
        return None

def get_process_command(pid):
    """íŠ¹ì • PIDì˜ ëª…ë ¹ì¤„ ê°€ì ¸ì˜¤ê¸°"""
    try:
        cmdline_path = f"/proc/{pid}/cmdline"
        with open(cmdline_path, "r") as f:
            cmdline = f.read().replace("\x00", " ").strip()
        return cmdline
    except FileNotFoundError:
        print(f"[DEBUG] PID {pid}ì— ëŒ€í•œ ëª…ë ¹ì¤„ íŒŒì¼ì„ ì°¾ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤: {cmdline_path}")
        return None
    except Exception as e:
        print(f"[ERROR] PID {pid} ëª…ë ¹ì¤„ ì½ê¸° ì˜¤ë¥˜: {e}")
        return None

def extract_yaml_info(cmdline, cwd):
    """ëª…ë ¹ì¤„ì—ì„œ YAML íŒŒì¼ ê²½ë¡œ ì¶”ì¶œ ë° ë‚´ìš© ì½ê¸°"""
    parts = cmdline.split()

    for part in parts:
        if part.endswith(".yaml") or part.endswith(".yml"):
            yaml_path = part
            abs_yaml_path = os.path.join(cwd, yaml_path) if not os.path.isabs(yaml_path) else yaml_path

            if os.path.exists(abs_yaml_path):
                try:
                    with open(abs_yaml_path, "r") as f:
                        yaml_data = yaml.safe_load(f)

                        model_info = yaml_data.get("model", {})
                        return {
                            "yaml_path": abs_yaml_path,
                            "llama_path": os.path.basename(model_info.get("llama_path", "N/A")),
                            "whisper_path": os.path.basename(model_info.get("whisper_path", "N/A")),
                            "beats_path": os.path.basename(model_info.get("beats_path", "N/A"))
                        }
                except yaml.YAMLError as e:
                    print(f"[ERROR] YAML íŒŒì¼ íŒŒì‹± ì˜¤ë¥˜: {abs_yaml_path}, ì˜¤ë¥˜: {e}")
                except Exception as e:
                    print(f"[ERROR] YAML íŒŒì¼ ì½ê¸° ì˜¤ë¥˜: {abs_yaml_path}, ì˜¤ë¥˜: {e}")
            else:
                print(f"[DEBUG] YAML íŒŒì¼ ê²½ë¡œê°€ ì¡´ì¬í•˜ì§€ ì•ŠìŠµë‹ˆë‹¤: {abs_yaml_path}")
    return None

def save_to_file(data):
    """GPU ìƒíƒœë¥¼ íŒŒì¼ì— ì €ì¥"""
    with open(LOG_FILE, "a") as f:
        f.write(data + "\n")

def send_to_slack(message):
    """ìŠ¬ë™ìœ¼ë¡œ ë©”ì‹œì§€ ì „ì†¡"""
    full_message = f"ğŸ–¥ï¸ *{SERVER_NAME}*\n{message}"
    requests.post(WEBHOOK_URL, json={"text": full_message})

def monitor_gpu():
    previous_states = {}  # ì´ì „ GPU ìƒíƒœ ì €ì¥
    already_notified_complete = set()  # í•™ìŠµ ì™„ë£Œ ì•Œë¦¼ ê¸°ë¡
    first_run = True

    while True:
        # 1ë‹¨ê³„: GPU ë©”ëª¨ë¦¬ ì‚¬ìš©ëŸ‰ ì¡°íšŒ
        gpu_usage = get_gpu_memory_usage()
        if not gpu_usage:
            print("[GPU Monitor] GPUê°€ ê°ì§€ë˜ì§€ ì•Šì•˜ìŠµë‹ˆë‹¤.")
            time.sleep(CHECK_INTERVAL)
            continue

        # 2ë‹¨ê³„: GPU í”„ë¡œì„¸ìŠ¤ ì •ë³´ ì¡°íšŒ
        gpu_process_info = get_gpu_process_info()

        message_lines = []  # ìŠ¬ë™ ë©”ì‹œì§€ ë¼ì¸
        changes_detected = False  # ìƒíƒœ ë³€í™” ê°ì§€ ì—¬ë¶€
        task_mapping = {}  # PIDì™€ ì‘ì—… ì •ë³´ ë§¤í•‘
        gpu_to_pid = {}  # GPUì™€ ì—°ê²°ëœ PID ë§¤í•‘

        for gpu_index, used_memory in gpu_usage.items():
            emoji = f"{gpu_index}ï¸âƒ£"
            previous_used = previous_states.get(gpu_index, 0)

            # GPU ìƒíƒœì— ë”°ë¥¸ ì•Œë¦¼ ì²˜ë¦¬
            if used_memory == 0:  # GPU ë©”ëª¨ë¦¬ê°€ 0MBì¼ ë•Œ
                if gpu_index not in already_notified_complete:
                    changes_detected = True
                    message_lines.append(f"{emoji} GPU {gpu_index}: 0MB âœ… í•™ìŠµ ì™„ë£Œ")
                    already_notified_complete.add(gpu_index)
            else:  # GPUê°€ ë‹¤ì‹œ ì‚¬ìš© ì¤‘ì¼ ê²½ìš°
                if gpu_index in already_notified_complete:
                    already_notified_complete.discard(gpu_index)  # ì™„ë£Œ ì•Œë¦¼ ì´ˆê¸°í™”
                if abs(used_memory - previous_used) >= ALERT_THRESHOLD:
                    changes_detected = True
                    message_lines.append(
                        f"{emoji} GPU {gpu_index}: {used_memory}MB (ë³€í™”: {previous_used}MB â†’ {used_memory}MB)"
                    )

                # í”„ë¡œì„¸ìŠ¤ë³„ ì •ë³´ ë° YAML í™•ì¸
                for gpu_uuid, gpu_data in gpu_process_info.items():
                    for process in gpu_data["processes"]:
                        pid = process["pid"]
                        cmdline = get_process_command(pid)
                        cwd = get_process_cwd(pid)

                        if cmdline and cwd:
                            yaml_info = extract_yaml_info(cmdline, cwd)
                            if yaml_info:
                                task_mapping[pid] = yaml_info
                                gpu_to_pid[gpu_index] = pid

            # GPU ì‚¬ìš©ëŸ‰ ì—…ë°ì´íŠ¸
            previous_states[gpu_index] = used_memory

        # ë™ì¼í•œ ì‘ì—…ì¸ì§€ í™•ì¸
        unique_tasks = set(
            (info["yaml_path"], info["llama_path"], info["whisper_path"], info["beats_path"])
            for info in task_mapping.values()
        )
        if len(unique_tasks) == 1:
            unique_task = next(iter(unique_tasks))
            message_lines.append(
                f":mag: ì‹¤í–‰ ì¤‘ì¸ ì‘ì—…: {unique_task[0]}\n"
                f"- llama_path: {unique_task[1]}\n"
                f"- whisper_path: {unique_task[2]}\n"
                f"- beats_path: {unique_task[3]}"
            )
        else:
            # ì„œë¡œ ë‹¤ë¥¸ ì‘ì—… ì •ë³´ ê°œë³„ ì•Œë¦¼
            for gpu_index, pid in gpu_to_pid.items():
                if pid in task_mapping:
                    task_info = task_mapping[pid]
                    message_lines.append(
                        f"{gpu_index}ï¸âƒ£ ì‹¤í–‰ ì¤‘ì¸ ì‘ì—…: {task_info['yaml_path']}\n"
                        f"- llama_path: {task_info['llama_path']}\n"
                        f"- whisper_path: {task_info['whisper_path']}\n"
                        f"- beats_path: {task_info['beats_path']}"
                    )

        # ìŠ¬ë™ ì•Œë¦¼ ì „ì†¡
        if first_run or changes_detected:
            if message_lines:  # ë©”ì‹œì§€ê°€ ìˆì„ ê²½ìš°ì—ë§Œ ì•Œë¦¼ ì „ì†¡
                full_message = "\n".join(message_lines)
                send_to_slack(full_message)
                save_to_file(full_message)

        first_run = False
        time.sleep(CHECK_INTERVAL)


if __name__ == "__main__":
    monitor_gpu()
